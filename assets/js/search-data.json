{
  
    
        "post0": {
            "title": "Multi Class Classification From Scratch (Part 2)",
            "content": "Date: 25/07/2022 . Author: @kavindu404 . Welcome to part 2 of the mini blog series on multi class classification from scratch. In first part, we used pixel similarity to predict the class of the digit. In this one, we will be building a simple neural network from scratch. Same as the last one, we start with importing fastai vision library and stacking up the data w.r.t classes like we did in the previous part. . from fastai.vision.all import * . path = untar_data(URLs.MNIST) Path.BASE_PATH = path path.ls() . . 100.03% [15687680/15683414 00:01&lt;00:00] (#2) [Path(&#39;training&#39;),Path(&#39;testing&#39;)] . zeros = (path/&#39;training&#39;/&#39;0&#39;).ls().sorted() ones = (path/&#39;training&#39;/&#39;1&#39;).ls().sorted() twos = (path/&#39;training&#39;/&#39;2&#39;).ls().sorted() threes = (path/&#39;training&#39;/&#39;3&#39;).ls().sorted() fours = (path/&#39;training&#39;/&#39;4&#39;).ls().sorted() fives = (path/&#39;training&#39;/&#39;5&#39;).ls().sorted() sixes = (path/&#39;training&#39;/&#39;6&#39;).ls().sorted() sevens = (path/&#39;training&#39;/&#39;7&#39;).ls().sorted() eights = (path/&#39;training&#39;/&#39;8&#39;).ls().sorted() nines = (path/&#39;training&#39;/&#39;9&#39;).ls().sorted() . stacked_zeros = torch.stack([tensor(Image.open(o)) for o in zeros]).float()/255 stacked_ones = torch.stack([tensor(Image.open(o)) for o in ones]).float()/255 stacked_twos = torch.stack([tensor(Image.open(o)) for o in twos]).float()/255 stacked_threes = torch.stack([tensor(Image.open(o)) for o in threes]).float()/255 stacked_fours = torch.stack([tensor(Image.open(o)) for o in fours]).float()/255 stacked_fives = torch.stack([tensor(Image.open(o)) for o in fives]).float()/255 stacked_sixes = torch.stack([tensor(Image.open(o)) for o in sixes]).float()/255 stacked_sevens = torch.stack([tensor(Image.open(o)) for o in sevens]).float()/255 stacked_eights = torch.stack([tensor(Image.open(o)) for o in eights]).float()/255 stacked_nines = torch.stack([tensor(Image.open(o)) for o in nines]).float()/255 . train_x = torch.cat([stacked_zeros, stacked_ones, stacked_twos, stacked_threes, stacked_fours, stacked_fives, stacked_sixes, stacked_sevens, stacked_eights, stacked_nines]).view(-1, 28*28) train_y = tensor([0]*len(zeros)+[1]*len(ones)+[2]*len(twos)+[3]*len(threes)+[4]*len(fours)+[5]*len(fives)+[6]*len(sixes)+[7]*len(sevens)+[8]*len(eights)+[9]*len(nines)).unsqueeze(1) train_x.shape, train_y.shape . (torch.Size([60000, 784]), torch.Size([60000, 1])) . Here, we create a dataset by coupling the image with its label. We do the same for the validation set. . train_dset = list(zip(train_x, train_y)) x, y = train_dset[100] x.shape, y.shape . (torch.Size([784]), torch.Size([1])) . valid_zeros = (path/&#39;testing&#39;/&#39;0&#39;).ls().sorted() valid_ones = (path/&#39;testing&#39;/&#39;1&#39;).ls().sorted() valid_twos = (path/&#39;testing&#39;/&#39;2&#39;).ls().sorted() valid_threes = (path/&#39;testing&#39;/&#39;3&#39;).ls().sorted() valid_fours = (path/&#39;testing&#39;/&#39;4&#39;).ls().sorted() valid_fives = (path/&#39;testing&#39;/&#39;5&#39;).ls().sorted() valid_sixes = (path/&#39;testing&#39;/&#39;6&#39;).ls().sorted() valid_sevens = (path/&#39;testing&#39;/&#39;7&#39;).ls().sorted() valid_eights = (path/&#39;testing&#39;/&#39;8&#39;).ls().sorted() valid_nines = (path/&#39;testing&#39;/&#39;9&#39;).ls().sorted() . valid_stacked_zeros = torch.stack([tensor(Image.open(o)) for o in valid_zeros]).float()/255 valid_stacked_ones = torch.stack([tensor(Image.open(o)) for o in valid_ones]).float()/255 valid_stacked_twos = torch.stack([tensor(Image.open(o)) for o in valid_twos]).float()/255 valid_stacked_threes = torch.stack([tensor(Image.open(o)) for o in valid_threes]).float()/255 valid_stacked_fours = torch.stack([tensor(Image.open(o)) for o in valid_fours]).float()/255 valid_stacked_fives = torch.stack([tensor(Image.open(o)) for o in valid_fives]).float()/255 valid_stacked_sixes = torch.stack([tensor(Image.open(o)) for o in valid_sixes]).float()/255 valid_stacked_sevens = torch.stack([tensor(Image.open(o)) for o in valid_sevens]).float()/255 valid_stacked_eights = torch.stack([tensor(Image.open(o)) for o in valid_eights]).float()/255 valid_stacked_nines = torch.stack([tensor(Image.open(o)) for o in valid_nines]).float()/255 . valid_x = torch.cat([valid_stacked_zeros, valid_stacked_ones, valid_stacked_twos, valid_stacked_threes, valid_stacked_fours, valid_stacked_fives, valid_stacked_sixes, valid_stacked_sevens, valid_stacked_eights, valid_stacked_nines]).view(-1, 28*28) valid_y = tensor([0]*len(valid_zeros)+[1]*len(valid_ones)+[2]*len(valid_twos)+[3]*len(valid_threes)+[4]*len(valid_fours)+[5]*len(valid_fives)+[6]*len(valid_sixes)+[7]*len(valid_sevens)+[8]*len(valid_eights)+[9]*len(valid_nines)).unsqueeze(1) valid_x.shape, valid_y.shape . (torch.Size([10000, 784]), torch.Size([10000, 1])) . valid_dset = list(zip(valid_x, valid_y)) . In the FastAI book, Jeremy explain a 7-step process that we gonna follow. The steps are as below; . Initialize the weights. | For each image, use these weights to predict the class. | Based on these predictions, calculate how good the model is (its loss). | Calculate the gradient, which measures for each weight, how changing that weight would change the loss | Step (that is, change) all the weights based on that calculation. | Go back to the step 2, and repeat the process. | Iterate until you decide to stop the training process (for instance, because the model is good enough or you don&#39;t want to wait any longer). | So first, we write a function to init the weights. . def init_param(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_param((28*28, 10)) bias = init_param(10) weights.shape . torch.Size([784, 10]) . In order to predict the class, we need a small model. So in the following function, we take the data as input and outputs the predictions. . def linear1(xb): return xb@weights+bias . Then, in the next step, we need a way to calculate the loss for the predictions. There are liple loss functions available depending on the application. In this case, we need a loss function that can compute the loss in a muti-categorical problem. Softmax is the most common loss function used in such cases. It requires all the predictions to sum to 1 and it tends to push the most likely activation to a much larger value compared to others. . def softmax(x): return torch.exp(x)/torch.exp(x).sum(dim=1, keepdim=True) . So now we define crossentropy loss to first apply softmax to the predictions and then to calculate the loss comparing them to the targets . def crossentropy_loss(inputs, targets): activations = softmax(inputs) return -activations[range(inputs.shape[0]), targets].log().mean() . Okay now we create dataloader objects for both training and validation sets. Note that each data point is having 784 features (28 * 28) and a corresponding label. . dl = DataLoader(train_dset, batch_size=256) xb,yb = first(dl) xb.shape, yb.shape . (torch.Size([256, 784]), torch.Size([256, 1])) . valid_dl = DataLoader(valid_dset, batch_size=256) . Let&#39;s grab a subset of the training set and get their predictions . batch = train_x[:4] batch.shape . torch.Size([4, 784]) . Note that for each input, there are 10 outputs. Once we input them to the softmax loss function, it outputs those 10 values in a way that they add up to 1 with the most probable labels with higher values. . preds = linear1(batch) preds.shape . torch.Size([4, 10]) . loss = crossentropy_loss(preds, train_y[:4]) loss . tensor(16.7473, grad_fn=&lt;NegBackward0&gt;) . loss.backward() weights.grad.shape,weights.grad.mean(),bias.grad . (torch.Size([784, 10]), tensor(2.4328e-10), tensor([-9.9999e-01, 7.6655e-01, 1.7359e-07, 5.4389e-04, 5.4135e-02, 3.6396e-07, 1.7450e-01, 4.2626e-03, 3.9071e-06, 2.6428e-07])) . Now we put all the steps together to calculate the gradients . def calc_grad(xb, yb, model): preds = model(xb) loss = crossentropy_loss(preds, yb) loss.backward() . Next we define the following function to train our model for a single epoch. It will take each batch from the data loader and will calculate the gradients. Then it will update the weights accordingly . def train_epoch(model, lr, param): for xb, yb in dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . Finally, we can package them allto train for multiple epochs . def train_model(model,lr, param, epochs): val_acc = [] for i in range (epochs): train_epoch(model, lr, param) val_acc.append(validate_epoch(model)) return val_acc . We also define functions to calculate train and validation accuracies. . def batch_accuracy(preds,yb): correct=preds.max(axis=1)[1]==yb return correct.float().mean() . def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . weights = init_param((28*28, 10)) bias = init_param(10) params = weights,bias lr = 1e-1 val_acc=(train_model(linear1, lr, params, 100)) plt.plot(range(100), val_acc), val_acc[-1] . ([&lt;matplotlib.lines.Line2D at 0x7f7b07cfe5f0&gt;], 0.621) . So our simple neural network is capable of classifying digits with a validation accuracy of 0.621 .",
            "url": "https://kavindu404.github.io/Blog/2022/10/03/Multiclass-Classification-from-Scratch-(Part-2).html",
            "relUrl": "/2022/10/03/Multiclass-Classification-from-Scratch-(Part-2).html",
            "date": " • Oct 3, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Multi Class Classification From Scratch",
            "content": "Date: 15/07/2022 . Author: @kavindu404 . In this mini blog series, I am implementing multiclass classifier for MNIST digits from scratch. In this part, I will be classifying the digits using pixel similarity. I will try to improve the performance in each part. First, let&#39;s import FastAI . from fastai.vision.all import * . /usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn&#39;t match a supported version! warnings.warn(&#34;urllib3 ({}) or chardet ({}) doesn&#39;t match a supported &#34; . MNIST dataset can be downloaded and extracted using untar_data() method. With FastAI, we can easily list the elements in the extracted derectory. . path = untar_data(URLs.MNIST) Path.BASE_PATH = path path.ls() . (#2) [Path(&#39;testing&#39;),Path(&#39;training&#39;)] . Let&#39;s first get training data into different objects. The ls() method returns an object of class L in FastAI.It has all the functionalities in python list() and some more. . zeros = (path/&#39;training&#39;/&#39;0&#39;).ls().sorted() ones = (path/&#39;training&#39;/&#39;1&#39;).ls().sorted() twos = (path/&#39;training&#39;/&#39;2&#39;).ls().sorted() threes = (path/&#39;training&#39;/&#39;3&#39;).ls().sorted() fours = (path/&#39;training&#39;/&#39;4&#39;).ls().sorted() fives = (path/&#39;training&#39;/&#39;5&#39;).ls().sorted() sixes = (path/&#39;training&#39;/&#39;6&#39;).ls().sorted() sevens = (path/&#39;training&#39;/&#39;7&#39;).ls().sorted() eights = (path/&#39;training&#39;/&#39;8&#39;).ls().sorted() nines = (path/&#39;training&#39;/&#39;9&#39;).ls().sorted() . zeros,ones,twos,threes,fours,fives,sixes,sevens,eights,nines . ((#5923) [Path(&#39;training/0/1.png&#39;),Path(&#39;training/0/1000.png&#39;),Path(&#39;training/0/10005.png&#39;),Path(&#39;training/0/10010.png&#39;),Path(&#39;training/0/10022.png&#39;),Path(&#39;training/0/10025.png&#39;),Path(&#39;training/0/10026.png&#39;),Path(&#39;training/0/10045.png&#39;),Path(&#39;training/0/10069.png&#39;),Path(&#39;training/0/10071.png&#39;)...], (#6742) [Path(&#39;training/1/10006.png&#39;),Path(&#39;training/1/10007.png&#39;),Path(&#39;training/1/1002.png&#39;),Path(&#39;training/1/10020.png&#39;),Path(&#39;training/1/10027.png&#39;),Path(&#39;training/1/1003.png&#39;),Path(&#39;training/1/10040.png&#39;),Path(&#39;training/1/10048.png&#39;),Path(&#39;training/1/10058.png&#39;),Path(&#39;training/1/10067.png&#39;)...], (#5958) [Path(&#39;training/2/10009.png&#39;),Path(&#39;training/2/10016.png&#39;),Path(&#39;training/2/10024.png&#39;),Path(&#39;training/2/10029.png&#39;),Path(&#39;training/2/10072.png&#39;),Path(&#39;training/2/10073.png&#39;),Path(&#39;training/2/10075.png&#39;),Path(&#39;training/2/10078.png&#39;),Path(&#39;training/2/10081.png&#39;),Path(&#39;training/2/10082.png&#39;)...], (#6131) [Path(&#39;training/3/10.png&#39;),Path(&#39;training/3/10000.png&#39;),Path(&#39;training/3/10011.png&#39;),Path(&#39;training/3/10031.png&#39;),Path(&#39;training/3/10034.png&#39;),Path(&#39;training/3/10042.png&#39;),Path(&#39;training/3/10052.png&#39;),Path(&#39;training/3/1007.png&#39;),Path(&#39;training/3/10074.png&#39;),Path(&#39;training/3/10091.png&#39;)...], (#5842) [Path(&#39;training/4/10013.png&#39;),Path(&#39;training/4/10018.png&#39;),Path(&#39;training/4/10033.png&#39;),Path(&#39;training/4/1004.png&#39;),Path(&#39;training/4/1006.png&#39;),Path(&#39;training/4/10060.png&#39;),Path(&#39;training/4/1008.png&#39;),Path(&#39;training/4/10103.png&#39;),Path(&#39;training/4/10104.png&#39;),Path(&#39;training/4/10114.png&#39;)...], (#5421) [Path(&#39;training/5/0.png&#39;),Path(&#39;training/5/100.png&#39;),Path(&#39;training/5/10008.png&#39;),Path(&#39;training/5/10015.png&#39;),Path(&#39;training/5/10030.png&#39;),Path(&#39;training/5/10035.png&#39;),Path(&#39;training/5/10049.png&#39;),Path(&#39;training/5/10051.png&#39;),Path(&#39;training/5/10056.png&#39;),Path(&#39;training/5/10062.png&#39;)...], (#5918) [Path(&#39;training/6/10017.png&#39;),Path(&#39;training/6/10032.png&#39;),Path(&#39;training/6/10036.png&#39;),Path(&#39;training/6/10037.png&#39;),Path(&#39;training/6/10044.png&#39;),Path(&#39;training/6/10053.png&#39;),Path(&#39;training/6/10076.png&#39;),Path(&#39;training/6/10089.png&#39;),Path(&#39;training/6/10101.png&#39;),Path(&#39;training/6/10108.png&#39;)...], (#6265) [Path(&#39;training/7/10002.png&#39;),Path(&#39;training/7/1001.png&#39;),Path(&#39;training/7/10014.png&#39;),Path(&#39;training/7/10019.png&#39;),Path(&#39;training/7/10039.png&#39;),Path(&#39;training/7/10046.png&#39;),Path(&#39;training/7/10050.png&#39;),Path(&#39;training/7/10063.png&#39;),Path(&#39;training/7/10077.png&#39;),Path(&#39;training/7/10086.png&#39;)...], (#5851) [Path(&#39;training/8/10001.png&#39;),Path(&#39;training/8/10012.png&#39;),Path(&#39;training/8/10021.png&#39;),Path(&#39;training/8/10041.png&#39;),Path(&#39;training/8/10054.png&#39;),Path(&#39;training/8/10057.png&#39;),Path(&#39;training/8/10061.png&#39;),Path(&#39;training/8/10064.png&#39;),Path(&#39;training/8/10066.png&#39;),Path(&#39;training/8/10079.png&#39;)...], (#5949) [Path(&#39;training/9/10003.png&#39;),Path(&#39;training/9/10004.png&#39;),Path(&#39;training/9/10023.png&#39;),Path(&#39;training/9/10028.png&#39;),Path(&#39;training/9/10038.png&#39;),Path(&#39;training/9/10043.png&#39;),Path(&#39;training/9/10047.png&#39;),Path(&#39;training/9/1005.png&#39;),Path(&#39;training/9/10055.png&#39;),Path(&#39;training/9/10059.png&#39;)...]) . Now that we have all the data seperated into objects, let&#39;s stack them up. . stacked_zeros = torch.stack([tensor(Image.open(o)) for o in zeros]).float()/255 stacked_ones = torch.stack([tensor(Image.open(o)) for o in ones]).float()/255 stacked_twos = torch.stack([tensor(Image.open(o)) for o in twos]).float()/255 stacked_threes = torch.stack([tensor(Image.open(o)) for o in threes]).float()/255 stacked_fours = torch.stack([tensor(Image.open(o)) for o in fours]).float()/255 stacked_fives = torch.stack([tensor(Image.open(o)) for o in fives]).float()/255 stacked_sixes = torch.stack([tensor(Image.open(o)) for o in sixes]).float()/255 stacked_sevens = torch.stack([tensor(Image.open(o)) for o in sevens]).float()/255 stacked_eights = torch.stack([tensor(Image.open(o)) for o in eights]).float()/255 stacked_nines = torch.stack([tensor(Image.open(o)) for o in nines]).float()/255 . stacked_zeros.shape, stacked_ones.shape, stacked_twos.shape, stacked_threes.shape, stacked_fours.shape, stacked_fives.shape, stacked_sixes.shape, stacked_sevens.shape, stacked_eights.shape, stacked_nines.shape, . (torch.Size([5923, 28, 28]), torch.Size([6742, 28, 28]), torch.Size([5958, 28, 28]), torch.Size([6131, 28, 28]), torch.Size([5842, 28, 28]), torch.Size([5421, 28, 28]), torch.Size([5918, 28, 28]), torch.Size([6265, 28, 28]), torch.Size([5851, 28, 28]), torch.Size([5949, 28, 28])) . In our first attempt, we will use pixel similarity. So, first, let&#39;s calculate the mean for each digit. . mean0 = stacked_zeros.mean(0) mean1 = stacked_ones.mean(0) mean2 = stacked_twos.mean(0) mean3 = stacked_threes.mean(0) mean4 = stacked_fours.mean(0) mean5 = stacked_fives.mean(0) mean6 = stacked_sixes.mean(0) mean7 = stacked_sevens.mean(0) mean8 = stacked_eights.mean(0) mean9 = stacked_nines.mean(0) . The mean for each digit represents the &#39;ideal&#39; digit that is expected. Let&#39;s take a look at the &#39;ideal&#39; 2. . df1 = pd.DataFrame(mean2[0:29,0:23]) df1.style.set_properties(**{&#39;font-size&#39;:&#39;4.5pt&#39;}).background_gradient(&#39;Greys&#39;) . &nbsp; 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 . 0 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000007 | 0.000142 | 0.000142 | 0.000006 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 1 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000011 | 0.000184 | 0.000234 | 0.000400 | 0.000471 | 0.000259 | 0.000369 | 0.000718 | 0.000733 | 0.001320 | 0.000560 | 0.000047 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 2 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000030 | 0.000301 | 0.001010 | 0.002387 | 0.004827 | 0.007155 | 0.010033 | 0.012604 | 0.014091 | 0.015811 | 0.015780 | 0.012331 | 0.008118 | 0.004130 | 0.001792 | 0.000594 | 0.000146 | 0.000008 | . 3 0.000000 | 0.000000 | 0.000007 | 0.000010 | 0.000056 | 0.001060 | 0.004104 | 0.010762 | 0.024223 | 0.045967 | 0.070977 | 0.100678 | 0.127955 | 0.151479 | 0.162052 | 0.160046 | 0.140632 | 0.108345 | 0.072146 | 0.043444 | 0.021461 | 0.008759 | 0.002672 | . 4 0.000000 | 0.000000 | 0.000042 | 0.000090 | 0.000819 | 0.006367 | 0.017791 | 0.042089 | 0.083421 | 0.142241 | 0.211767 | 0.292313 | 0.370494 | 0.431761 | 0.461901 | 0.456149 | 0.417914 | 0.336929 | 0.243804 | 0.160297 | 0.089220 | 0.040629 | 0.012857 | . 5 0.000000 | 0.000000 | 0.000077 | 0.000273 | 0.003049 | 0.016349 | 0.045503 | 0.096712 | 0.171761 | 0.263224 | 0.362981 | 0.463160 | 0.547239 | 0.610263 | 0.644565 | 0.647456 | 0.608250 | 0.530123 | 0.407579 | 0.281021 | 0.173409 | 0.088314 | 0.033626 | . 6 0.000000 | 0.000000 | 0.000053 | 0.000680 | 0.006591 | 0.028900 | 0.076292 | 0.151805 | 0.242472 | 0.341647 | 0.436100 | 0.516924 | 0.570205 | 0.603516 | 0.622732 | 0.634839 | 0.627733 | 0.584579 | 0.494698 | 0.369531 | 0.244626 | 0.136664 | 0.056396 | . 7 0.000000 | 0.000000 | 0.000254 | 0.000965 | 0.010361 | 0.040237 | 0.099327 | 0.176339 | 0.259723 | 0.339625 | 0.407273 | 0.454401 | 0.472272 | 0.475716 | 0.483725 | 0.502393 | 0.532844 | 0.546947 | 0.510726 | 0.415592 | 0.291848 | 0.174315 | 0.079336 | . 8 0.000000 | 0.000045 | 0.000288 | 0.001272 | 0.011794 | 0.044498 | 0.102871 | 0.166226 | 0.228230 | 0.278922 | 0.319372 | 0.333384 | 0.328697 | 0.318813 | 0.326290 | 0.363595 | 0.431744 | 0.499352 | 0.508834 | 0.437793 | 0.316499 | 0.190417 | 0.088839 | . 9 0.000000 | 0.000000 | 0.000267 | 0.001539 | 0.011091 | 0.039959 | 0.085990 | 0.129770 | 0.165140 | 0.192895 | 0.213386 | 0.212083 | 0.195751 | 0.186895 | 0.201606 | 0.266368 | 0.371373 | 0.475721 | 0.510332 | 0.450774 | 0.323187 | 0.191269 | 0.087439 | . 10 0.000000 | 0.000000 | 0.000130 | 0.001378 | 0.007421 | 0.029077 | 0.060358 | 0.081593 | 0.101843 | 0.116352 | 0.123059 | 0.116682 | 0.104919 | 0.104716 | 0.142872 | 0.234735 | 0.366604 | 0.481890 | 0.516487 | 0.450063 | 0.313075 | 0.176987 | 0.075751 | . 11 0.000000 | 0.000000 | 0.000000 | 0.000766 | 0.005266 | 0.018284 | 0.033207 | 0.043408 | 0.053382 | 0.062493 | 0.064077 | 0.060981 | 0.061179 | 0.081220 | 0.144231 | 0.261926 | 0.398805 | 0.500654 | 0.514638 | 0.435455 | 0.288501 | 0.150212 | 0.058968 | . 12 0.000000 | 0.000000 | 0.000000 | 0.000292 | 0.003241 | 0.010065 | 0.016726 | 0.023751 | 0.033803 | 0.041343 | 0.046381 | 0.055371 | 0.073395 | 0.119073 | 0.205897 | 0.329536 | 0.446791 | 0.518040 | 0.503421 | 0.401478 | 0.248775 | 0.118531 | 0.044476 | . 13 0.000000 | 0.000000 | 0.000032 | 0.000380 | 0.002123 | 0.007130 | 0.016208 | 0.028661 | 0.045382 | 0.063764 | 0.087072 | 0.119171 | 0.161834 | 0.229378 | 0.320824 | 0.418851 | 0.502115 | 0.529520 | 0.473732 | 0.349567 | 0.202185 | 0.091573 | 0.035927 | . 14 0.000000 | 0.000000 | 0.000000 | 0.000631 | 0.003544 | 0.013647 | 0.035809 | 0.069251 | 0.108837 | 0.153193 | 0.204482 | 0.261094 | 0.323508 | 0.397957 | 0.470263 | 0.534277 | 0.559740 | 0.528731 | 0.437916 | 0.300230 | 0.168766 | 0.080268 | 0.038659 | . 15 0.000000 | 0.000000 | 0.000069 | 0.002358 | 0.011354 | 0.039603 | 0.090194 | 0.155878 | 0.224798 | 0.295254 | 0.366840 | 0.438308 | 0.511417 | 0.578410 | 0.619545 | 0.628696 | 0.593969 | 0.520419 | 0.403039 | 0.271179 | 0.162587 | 0.093511 | 0.061005 | . 16 0.000000 | 0.000000 | 0.000350 | 0.006034 | 0.030797 | 0.089589 | 0.177901 | 0.269840 | 0.358496 | 0.437472 | 0.502642 | 0.569108 | 0.634937 | 0.679840 | 0.690350 | 0.666253 | 0.606259 | 0.510305 | 0.395925 | 0.281850 | 0.196662 | 0.140591 | 0.106600 | . 17 0.000000 | 0.000000 | 0.000648 | 0.014614 | 0.062288 | 0.152536 | 0.268917 | 0.373017 | 0.453545 | 0.510708 | 0.556134 | 0.610725 | 0.656431 | 0.686115 | 0.683940 | 0.651334 | 0.590322 | 0.509432 | 0.420484 | 0.334785 | 0.265909 | 0.211504 | 0.168157 | . 18 0.000000 | 0.000000 | 0.000675 | 0.025045 | 0.096128 | 0.211982 | 0.339039 | 0.442429 | 0.504724 | 0.550516 | 0.594093 | 0.627278 | 0.656336 | 0.670207 | 0.655604 | 0.622225 | 0.578423 | 0.524000 | 0.467761 | 0.405183 | 0.347683 | 0.294237 | 0.237217 | . 19 0.000000 | 0.000000 | 0.001110 | 0.032870 | 0.117689 | 0.242600 | 0.378972 | 0.491348 | 0.566807 | 0.618971 | 0.651180 | 0.668537 | 0.669368 | 0.650098 | 0.613270 | 0.575419 | 0.541508 | 0.513792 | 0.488711 | 0.452865 | 0.406129 | 0.347430 | 0.274100 | . 20 0.000000 | 0.000009 | 0.001803 | 0.034276 | 0.119279 | 0.234893 | 0.377356 | 0.504160 | 0.607640 | 0.673011 | 0.690975 | 0.682460 | 0.644020 | 0.586525 | 0.527870 | 0.482407 | 0.461993 | 0.455073 | 0.457337 | 0.437818 | 0.394623 | 0.330521 | 0.248283 | . 21 0.000000 | 0.000122 | 0.001963 | 0.026058 | 0.091249 | 0.188354 | 0.313729 | 0.440901 | 0.550462 | 0.618395 | 0.625133 | 0.591058 | 0.529502 | 0.456810 | 0.395368 | 0.356391 | 0.344007 | 0.349045 | 0.354380 | 0.343302 | 0.304571 | 0.245597 | 0.176619 | . 22 0.000000 | 0.000000 | 0.001066 | 0.012793 | 0.047181 | 0.108409 | 0.194192 | 0.289751 | 0.372962 | 0.419609 | 0.424284 | 0.390612 | 0.336123 | 0.277596 | 0.234563 | 0.209485 | 0.204407 | 0.207852 | 0.212406 | 0.202193 | 0.177242 | 0.140470 | 0.098799 | . 23 0.000000 | 0.000000 | 0.000076 | 0.002722 | 0.012580 | 0.032933 | 0.063455 | 0.101813 | 0.135328 | 0.154938 | 0.158624 | 0.146665 | 0.126948 | 0.106317 | 0.091593 | 0.081452 | 0.079375 | 0.077296 | 0.076020 | 0.071620 | 0.063231 | 0.051806 | 0.035349 | . 24 0.000000 | 0.000000 | 0.000000 | 0.000052 | 0.000743 | 0.002455 | 0.005081 | 0.008940 | 0.011869 | 0.014211 | 0.015518 | 0.016728 | 0.017879 | 0.017852 | 0.017593 | 0.016117 | 0.015332 | 0.013918 | 0.012382 | 0.010117 | 0.008858 | 0.007724 | 0.006063 | . 25 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000181 | 0.000274 | 0.000274 | 0.000280 | 0.000440 | 0.000629 | 0.000767 | 0.001215 | 0.001755 | 0.001911 | 0.001793 | 0.001603 | 0.001268 | 0.000905 | 0.000796 | 0.000546 | 0.000224 | . 26 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 27 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . im = stacked_ones[1] show_image(im) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f588d51ed00&gt; . Now, let&#39;s collect validation dataset and stack them up. . valid_zeros = (path/&#39;testing&#39;/&#39;0&#39;).ls().sorted() valid_ones = (path/&#39;testing&#39;/&#39;1&#39;).ls().sorted() valid_twos = (path/&#39;testing&#39;/&#39;2&#39;).ls().sorted() valid_threes = (path/&#39;testing&#39;/&#39;3&#39;).ls().sorted() valid_fours = (path/&#39;testing&#39;/&#39;4&#39;).ls().sorted() valid_fives = (path/&#39;testing&#39;/&#39;5&#39;).ls().sorted() valid_sixes = (path/&#39;testing&#39;/&#39;6&#39;).ls().sorted() valid_sevens = (path/&#39;testing&#39;/&#39;7&#39;).ls().sorted() valid_eights = (path/&#39;testing&#39;/&#39;8&#39;).ls().sorted() valid_nines = (path/&#39;testing&#39;/&#39;9&#39;).ls().sorted() . valid_stacked_zeros = torch.stack([tensor(Image.open(o)) for o in valid_zeros]).float()/255 valid_stacked_ones = torch.stack([tensor(Image.open(o)) for o in valid_ones]).float()/255 valid_stacked_twos = torch.stack([tensor(Image.open(o)) for o in valid_twos]).float()/255 valid_stacked_threes = torch.stack([tensor(Image.open(o)) for o in valid_threes]).float()/255 valid_stacked_fours = torch.stack([tensor(Image.open(o)) for o in valid_fours]).float()/255 valid_stacked_fives = torch.stack([tensor(Image.open(o)) for o in valid_fives]).float()/255 valid_stacked_sixes = torch.stack([tensor(Image.open(o)) for o in valid_sixes]).float()/255 valid_stacked_sevens = torch.stack([tensor(Image.open(o)) for o in valid_sevens]).float()/255 valid_stacked_eights = torch.stack([tensor(Image.open(o)) for o in valid_eights]).float()/255 valid_stacked_nines = torch.stack([tensor(Image.open(o)) for o in valid_nines]).float()/255 . In order to get the pixel similarity, we have to get the distance from the &#39;ideal&#39; digit for each digit. First, we have to check the distance for each &#39;ideal&#39; digit and then choose the closest one. In distance() method, we simply get the distance between two inputs. In min_distance() method, we find the closest &#39;ideal&#39; digit for a given input. In is_correct() method, we can simply determine whether our prediction using pixel similarity is correct or not. . def distance(x,y): return (x-y).abs().mean((-1,-2)) . mean_vec = [mean0, mean1, mean2, mean3, mean4, mean5, mean6, mean7, mean8, mean9] def min_distance(x): distances = [distance(x, o) for o in mean_vec] return distances.index(min(distances)) . def is_correct(num, x): return num == min_distance(x) . Let&#39;s check with some inputs. . is_correct(4, valid_stacked_ones[140]) . False . Now that we have guranteed it is working fine, let&#39;s calculate the accuracy of the model. In here, we will simply get the correct prediction per each class and then get the mean of it. . acc_zeros = tensor([is_correct(0,o) for o in valid_stacked_zeros]).float().mean() acc_ones = tensor([is_correct(1,o) for o in valid_stacked_ones]).float().mean() acc_twos = tensor([is_correct(2,o) for o in valid_stacked_twos]).float().mean() acc_threes = tensor([is_correct(3,o) for o in valid_stacked_threes]).float().mean() acc_fours = tensor([is_correct(4,o) for o in valid_stacked_fours]).float().mean() acc_fives = tensor([is_correct(5,o) for o in valid_stacked_fives]).float().mean() acc_sixes = tensor([is_correct(6,o) for o in valid_stacked_sixes]).float().mean() acc_sevens = tensor([is_correct(7,o) for o in valid_stacked_sevens]).float().mean() acc_eights = tensor([is_correct(8,o) for o in valid_stacked_eights]).float().mean() acc_nines = tensor([is_correct(9,o) for o in valid_stacked_nines]).float().mean() acc= tensor([acc_zeros, acc_ones, acc_twos, acc_threes, acc_fours, acc_fives, acc_sixes, acc_sevens, acc_eights, acc_nines]).mean() acc . tensor(0.6610) . So, we have an accuracy of 66.1%. Given that we only considered pixel similarity, it is a good result. In next part, let&#39;s try to improve from here. .",
            "url": "https://kavindu404.github.io/Blog/2022/10/03/Multiclass-Classification-from-Scratch-(Part-1).html",
            "relUrl": "/2022/10/03/Multiclass-Classification-from-Scratch-(Part-1).html",
            "date": " • Oct 3, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Checkout my personal website here :). .",
          "url": "https://kavindu404.github.io/Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kavindu404.github.io/Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}